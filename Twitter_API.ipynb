{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 67-364 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, we have to download the python libraries and write the helper functions needed to produce the data; and they are as follows:\n",
    "#### 1) Tweepy: \n",
    "Twitter API used to gather Tweets from Twitter\n",
    "#### 2) Pandas, matplotlib, and seaborn: \n",
    "Data visualization libraries\n",
    "#### 3) Textblob, networkx, and nltk: \n",
    "Data analysis libraries\n",
    "#### 4) Others: \n",
    "libraries used to assist with the analysis step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\andrew\\anaconda3\\lib\\site-packages (0.15.3)\nRequirement already satisfied: nltk>=3.1 in c:\\users\\andrew\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\nRequirement already satisfied: six in c:\\users\\andrew\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.14.0)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6e2d09eef00c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOAuthHandler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import csv\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "#helper function used to remove the URL from a given string. This is helpful as the Tweets we get from the Twitter API often\n",
    "#contains the url of the Tweet, which could hinder the accuracy of our sentiment analysis tools.\n",
    "#Requires: a string\n",
    "#Ensures: The same txt string with url's removed.\n",
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are getting information from Twitter, authentication matters because it enables Twitter to keep their networks secure by permitting only authenticated users (or processes) to access its protected resources. For privacy reasons, we have commented out our key and access tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'Your consumer key here'\n",
    "consumer_secret = 'Your consumer secret here'\n",
    "access_token = 'Your access token here'\n",
    "access_secret = 'Your access secret here'\n",
    "\n",
    "try:\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    \n",
    "except:\n",
    "    print(\"Error: Authentication Failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"\"\"AramexUAE OR AramexQatar OR AramexKwi OR AramexQa OR Aramex_KSA OR UPS_Kuwait\"\"\"\n",
    "date_since = \"2019-12-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(1000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"aramex_gcc_en.csv\", \"w+\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\"])\n",
    "\n",
    "#general information saved for analysis\n",
    "aramex_gcc_en = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    filtered_text = tweet.full_text\n",
    "    \n",
    "    filtered_text = remove_url(filtered_text)\n",
    "    \n",
    "    screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "    location = (tweet.user.location.encode('utf-8'))\n",
    "    \n",
    "    if (\"thanks for reaching out\" not in filtered_text):\n",
    "        aramex_gcc_en.append(tweet.full_text)\n",
    "        counter += 1\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location])\n",
    "        \n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}