{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweepy is a python library to access Twitter API.\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'TwBvCfS4R1EieqZNPzhrnANHr'\n",
    "consumer_secret = 'sRdRTvOBrY9juvI0Sb03GS8rEvEN4M9l1vYqaxj1ZR6JOR3H8m'\n",
    "access_token = '3162328915-37LW2nu1fxi5dQIi9O41CA4M7C6E3qF0vQOLmrs'\n",
    "access_token_secret = 'Ce88SfJbCYMNqiD9ZSaEo6h9xiygtyNUGMJqKRZKizStj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'96683cc9126741d1'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "place_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxTweets = 1\n",
    "\n",
    "# #Saving the tweets in a csv file:\n",
    "# csvFile = open(\"final_tweets.csv\", \"a\")\n",
    "# csvWriter = csv.writer(csvFile)\n",
    "# csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Keyword\"])\n",
    "\n",
    "# for month in range(3,12):\n",
    "#     for day in range(1,30):\n",
    "#         date_since = f\"2020-{month}-{day}\"\n",
    "#         date_until = f\"2020-{month}-{day+1}\"\n",
    "#         for i,tweet in enumerate(sntwitter.TwitterSearchScraper('covid19' + 'since:2020-4-15 until:2020-4-16 lang:en place:96683cc9126741d1').get_items()):\n",
    "\n",
    "#             if i > maxTweets:\n",
    "#                 break\n",
    "            \n",
    "#             time_created = tweet.date.strftime(\"%m/%d/%Y\")\n",
    "#             filtered_text = remove_url(tweet.content)\n",
    "#             screen_user = tweet.username\n",
    "\n",
    "#             if ('covid' in filtered_text.lower()):\n",
    "#                 keyword = \"COVID\"\n",
    "#             else:\n",
    "#                 keyword = \"corona\"\n",
    "#             print(filtered_text)\n",
    "#             print(\"----------------\")\n",
    "#             csvWriter.writerow([time_created, filtered_text, screen_user, keyword])\n",
    "#         print(f\"Month: {month}, Day: {day}\")\n",
    "\n",
    "# csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxTweets = 3000\n",
    "base = \"(covid or corona or covid-19)\"\n",
    "# \"(covid OR corona OR covid-19) AND (hoax OR virus OR fake news OR pandemic) OR (covid OR corona OR covid-19)\"\n",
    "tweets = sntwitter.TwitterSearchScraper(\"covid OR corona OR covid-19 OR pandemic OR virus\" + 'since:2020-4-1 until:2020-04-30 lang:en place:96683cc9126741d1').get_items()\n",
    "i = 0\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"omega_final_tweets.csv\", \"a\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "# csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Keyword\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    time_created = tweet.date.strftime(\"%m/%d/%Y\")\n",
    "    filtered_text = remove_url(tweet.content)\n",
    "    screen_user = tweet.username\n",
    "\n",
    "    if ('covid' in filtered_text.lower()):\n",
    "        keyword = \"COVID\"\n",
    "    if ('corona' in filtered_text.lower()):\n",
    "        keyword = \"corona\"\n",
    "    # if(keyword):\n",
    "    print(i)\n",
    "    i += 1\n",
    "    print(filtered_text)\n",
    "    print(time_created)\n",
    "    print(\"----------------\")\n",
    "    csvWriter.writerow([time_created, filtered_text, screen_user, keyword])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.close()"
   ]
  }
 ]
}