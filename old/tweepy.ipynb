{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 67-364 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, we have to download the python libraries and write the helper functions needed to produce the data; and they are as follows:\n",
    "#### 1) Tweepy: \n",
    "Twitter API used to gather Tweets from Twitter\n",
    "#### 2) Pandas, matplotlib, and seaborn: \n",
    "Data visualization libraries\n",
    "#### 3) Textblob, networkx, and nltk: \n",
    "Data analysis libraries\n",
    "#### 4) Others: \n",
    "libraries used to assist with the analysis step\n"
   ]
  },
  {
   "source": [
    "## Features\n",
    "\n",
    "1. Tweet Text\n",
    "2. Geo-location\n",
    "3. Date\n",
    "4. Believes / Does not believe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\andrew\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\andrew\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\andrew\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import csv\n",
    "import urllib\n",
    "import pprint\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "#helper function used to remove the URL from a given string. This is helpful as the Tweets we get from the Twitter API often\n",
    "#contains the url of the Tweet, which could hinder the accuracy of our sentiment analysis tools.\n",
    "#Requires: a string\n",
    "#Ensures: The same txt string with url's removed.\n",
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are getting information from Twitter, authentication matters because it enables Twitter to keep their networks secure by permitting only authenticated users (or processes) to access its protected resources. For privacy reasons, we have commented out our key and access tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'TwBvCfS4R1EieqZNPzhrnANHr'\n",
    "consumer_secret = 'sRdRTvOBrY9juvI0Sb03GS8rEvEN4M9l1vYqaxj1ZR6JOR3H8m'\n",
    "access_token = '3162328915-37LW2nu1fxi5dQIi9O41CA4M7C6E3qF0vQOLmrs'\n",
    "access_secret = 'Ce88SfJbCYMNqiD9ZSaEo6h9xiygtyNUGMJqKRZKizStj'\n",
    "\n",
    "try:\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "        \n",
    "except:\n",
    "    print(\"Error: Authentication Failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'96683cc9126741d1'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "place_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"covid-19 and place:%s\" % place_id\n",
    "date_since = \"2020-8-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(30000)\n",
    "\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"COVID-19_tweets.csv\", \"a\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "# csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\", \"Belief\", \"Keywords_used\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "        time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "        filtered_text = tweet.full_text\n",
    "        \n",
    "        filtered_text = remove_url(filtered_text)\n",
    "        \n",
    "        screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "        location = (tweet.user.location.encode('utf-8'))    \n",
    "\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location, \".\",\"keywords\"])\n",
    "        \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search words and Date\n",
    "search_words = \"corona and place:%s\" % place_id\n",
    "date_since = \"2020-8-1\"\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_words,\n",
    "                   lang=\"en\",\n",
    "                   tweet_mode = 'extended',\n",
    "                   since=date_since).items(0000)\n",
    "\n",
    "#Saving the tweets in a csv file:\n",
    "csvFile = open(\"corona_tweets.csv\", \"a\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Writing the header of the csv file\n",
    "csvWriter.writerow([\"Date\", \"Tweet\", \"User\", \"Location\", \"Belief\", \"Keywords_used\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "        time_created = tweet.created_at.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "        filtered_text = tweet.full_text\n",
    "        \n",
    "        filtered_text = remove_url(filtered_text)\n",
    "        \n",
    "        screen_user = (tweet.user.screen_name.encode('utf-8'))\n",
    "\n",
    "        location = (tweet.user.location.encode('utf-8'))    \n",
    "\n",
    "        csvWriter.writerow([time_created, filtered_text, screen_user, location, \".\",\"keywords\"])\n",
    "        \n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "An error occured during an HTTP request: HTTP Error 404: Not Found\n",
      "Try to open in browser: https://twitter.com/search?q=europe%20refugees%20since%3A2015-05-01%20until%3A2015-09-30&src=typd\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 343, in getJsonResponse\n",
      "    response = opener.open(url)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\urllib\\request.py\", line 531, in open\n",
      "    response = meth(req, response)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\urllib\\request.py\", line 641, in http_response\n",
      "    'http', request, response, code, msg, hdrs)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\urllib\\request.py\", line 569, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\urllib\\request.py\", line 649, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 404: Not Found\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-dc1c22bcde2f>\", line 12, in <module>\n",
      "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 65, in getTweets\n",
      "    json = TweetManager.getJsonResponse(tweetCriteria, refreshCursor, cookieJar, proxy, user_agent, debug=debug)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py\", line 348, in getJsonResponse\n",
      "    sys.exit()\n",
      "SystemExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Andrew\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Search words and Date\n",
    "search_words = \"corona and place:%s\" % place_id\n",
    "\n",
    "# To Keep or Remove Retweets\n",
    "search_words = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch('europe refugees')\\\n",
    "                                           .setSince(\"2015-05-01\")\\\n",
    "                                           .setUntil(\"2015-09-30\")\\\n",
    "                                           .setMaxTweets(1)\n",
    "                                           \n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "# for tweet in tweets:\n",
    "#         print(tweet.date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}